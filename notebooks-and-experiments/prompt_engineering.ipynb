{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH6kL6u-io1o"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install --upgrade pip\n",
        "!pip install -q transformers\n",
        "!pip install peft\n",
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3_cDMSmmqPv",
        "outputId": "6a072ddd-564d-45c1-e307-6e8788d5e8de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import string\n",
        "import torch\n",
        "import transformers\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "wFrcU6aQkStb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading model and the tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "1cQbRVe84V9G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"translate English to German: How old are you?\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "outputs = model.generate(input_ids)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_QIxxBH5wdr",
        "outputId": "38838d88-9dee-439b-aa29-a3122624046f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> Wie alte sind Sie?</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Write an SQL query to calculate the total salary expenditure for all employees in the 'employees' table.\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "\n",
        "outputs = model.generate(input_ids)\n",
        "print(tokenizer.decode(outputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "344NY89B6vkD",
        "outputId": "24c6d7dd-5502-45a7-f27b-7d13e0fd43f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pad> t = t.salary('<unk>') t = t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Generation with Prompt engineering"
      ],
      "metadata": {
        "id": "A6aqHbZgO4CB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "zero shot inference"
      ],
      "metadata": {
        "id": "euXNAZwGReEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = 'lost time traveller'\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Prompt:\n",
        "Write a story about {topic}\n",
        "\n",
        "Story:\n",
        "    \"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')"
      ],
      "metadata": {
        "id": "O8i5GWeT67TC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=75,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBiUhqoPRLCk",
        "outputId": "b01b333d-6c86-4ab9-ff1e-6e1f6863bb3b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Prompt:\n",
            "Write a story about lost time traveller\n",
            "\n",
            "Story:\n",
            "    \n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "The story begins in the year 2021. A man named John is a time traveller. He travels back in time to the year 2021. He travels back to the year 2021. He travels back to the year 2021. He travels back to the year 2021. He travels back to the year 2021. He travels\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One shot Inference"
      ],
      "metadata": {
        "id": "L2heOdV_W-Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = 'A lost sea sailor stuck at a remote island'\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Prompt:\n",
        "Write a story about a lost time traveler.\n",
        "\n",
        "Story:\n",
        "The time traveler stumbled out of the portal into an unfamiliar landscape. Confused and disoriented, he realized that he had lost his way in time. Now, he must find a way back to his own era before he becomes lost in the currents of time forever.\n",
        "\n",
        "Prompt:\n",
        "Write a story about {topic}\n",
        "\n",
        "Story:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')"
      ],
      "metadata": {
        "id": "z1DOelLdRs1b"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=75,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwSBpqIvVMs4",
        "outputId": "54fb3989-6151-4c7a-cd2c-5cd53a95a7b9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Prompt:\n",
            "Write a story about a lost time traveler.\n",
            "\n",
            "Story:\n",
            "The time traveler stumbled out of the portal into an unfamiliar landscape. Confused and disoriented, he realized that he had lost his way in time. Now, he must find a way back to his own era before he becomes lost in the currents of time forever.\n",
            "\n",
            "Prompt:\n",
            "Write a story about A lost sea sailor stuck at a remote island\n",
            "\n",
            "Story:\n",
            "\n",
            "    \n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "The sea sailor was lost at sea. He was stranded on a remote island. He was unable to find a way back to shore. He decided to stay on the island.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few shot Inference"
      ],
      "metadata": {
        "id": "MgJCklpbXBFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic = 'A lost astronaut stranded on an unknown planet'\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Prompt:\n",
        "Write a story about a lost time traveler.\n",
        "\n",
        "Story:\n",
        "The time traveler stumbled out of the portal into an unfamiliar landscape. Confused and disoriented, he realized that he had lost his way in time. Now, he must find a way back to his own era before he becomes lost in the currents of time forever.\n",
        "\n",
        "Prompt:\n",
        "Write a story about a lost sea sailor stuck at a remote island.\n",
        "\n",
        "Story:\n",
        "The sailor's ship was wrecked in a violent storm, leaving him stranded on a desolate island in the heart of the vast ocean. With no sign of rescue in sight, he must summon all his courage and resourcefulness to survive in this harsh, unforgiving environment. Alone and facing countless challenges, he embarks on a journey of self-discovery, drawing strength from the untamed beauty of the island and the endless expanse of the sea that surrounds it.\n",
        "\n",
        "Prompt:\n",
        "Write a story about a lost hiker trapped in a mysterious forest.\n",
        "\n",
        "Story:\n",
        "A hiker loses his way in a dense forest, surrounded by towering trees and eerie silence. With no sense of direction, he faces the challenge of finding his way back to safety, navigating through shadows and unknown dangers lurking in the darkness.\n",
        "\n",
        "Prompt:\n",
        "Write a story about {topic}\n",
        "\n",
        "Story:\n",
        "    \"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')"
      ],
      "metadata": {
        "id": "_1b5CpRrVQFg"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = tokenizer.decode(\n",
        "        model.generate(\n",
        "            inputs[\"input_ids\"],\n",
        "            max_new_tokens=75,\n",
        "        )[0],\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2zWs6lDWvRP",
        "outputId": "ce22d215-ae4e-43a5-ba92-a598e2e12506"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Prompt:\n",
            "Write a story about a lost time traveler.\n",
            "\n",
            "Story:\n",
            "The time traveler stumbled out of the portal into an unfamiliar landscape. Confused and disoriented, he realized that he had lost his way in time. Now, he must find a way back to his own era before he becomes lost in the currents of time forever.\n",
            "\n",
            "Prompt:\n",
            "Write a story about a lost sea sailor stuck at a remote island.\n",
            "\n",
            "Story:\n",
            "The sailor's ship was wrecked in a violent storm, leaving him stranded on a desolate island in the heart of the vast ocean. With no sign of rescue in sight, he must summon all his courage and resourcefulness to survive in this harsh, unforgiving environment. Alone and facing countless challenges, he embarks on a journey of self-discovery, drawing strength from the untamed beauty of the island and the endless expanse of the sea that surrounds it.\n",
            "\n",
            "Prompt:\n",
            "Write a story about a lost hiker trapped in a mysterious forest.\n",
            "\n",
            "Story:\n",
            "A hiker loses his way in a dense forest, surrounded by towering trees and eerie silence. With no sense of direction, he faces the challenge of finding his way back to safety, navigating through shadows and unknown dangers lurking in the darkness.\n",
            "\n",
            "Prompt:\n",
            "Write a story about A lost astronaut stranded on an unknown planet\n",
            "\n",
            "Story:\n",
            "    \n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "The astronaut, Buzz Aldrin, was on his way to the Moon. He was stranded on an unknown planet. Buzz was unable to contact Earth because he was lost in space. He was rescued by a spaceship.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXpaZzLtWzTe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}